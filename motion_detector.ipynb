{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from imutils.video import VideoStream\n",
    "import argparse\n",
    "import datetime\n",
    "import imutils\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize video path and minimum area (used to eliminate noise)\n",
    "video = 'high1.avi'\n",
    "min_area = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vs = cv2.VideoCapture(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the first frame in the video stream\n",
    "firstFrame = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the frames of the video\n",
    "while True:\n",
    "    # grab the current frame and initialize the occupied/unoccupied text\n",
    "    frame = vs.read()\n",
    "    frame = frame if video == None else frame[1]\n",
    "    text = \"Unoccupied\"\n",
    "    # if the frame could not be grabbed, then we have reached the end of the video\n",
    "    if frame is None:\n",
    "        break\n",
    "    # resize the frame, convert it to grayscale, and blur it\n",
    "    frame = imutils.resize(frame, width=500)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "    # if the first frame is None, initialize it\n",
    "    if firstFrame is None:\n",
    "        firstFrame = gray\n",
    "        continue\n",
    "    # compute the absolute difference between the current frame and first frame\n",
    "    frameDelta = cv2.absdiff(firstFrame, gray)\n",
    "    thresh = cv2.threshold(frameDelta, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "    # dilate the thresholded image to fill in holes, then find contours on thresholded image\n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    # loop over the contours\n",
    "    for c in cnts:\n",
    "        # if the contour is too small, ignore it\n",
    "        if cv2.contourArea(c) < min_area:\n",
    "            continue\n",
    "        # compute the bounding box for the contour, draw it on the frame,\n",
    "        # and update the text\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        text = \"Occupied\"\n",
    "        # draw the text and timestamp on the frame\n",
    "        cv2.putText(frame, \"Room Status: {}\".format(text), (10, 20),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "        cv2.putText(frame, datetime.datetime.now().strftime(\"%A %d %B %Y %I:%M:%S%p\"),\n",
    "            (10, frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 255), 1)\n",
    "        # show the frame and record if the user presses a key\n",
    "        cv2.imshow(\"Security Feed\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        # if the `q` key is pressed, break from the lop\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "# cleanup the camera and close any open windows\n",
    "vs.stop() if video == None else vs.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from scipy.spatial import distance as dist\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "class CentroidTracker():\n",
    "    def __init__(self, maxDisappeared=50):\n",
    "        # initialize the next unique object ID along with two ordered dictionaries used to keep track of mapping a given object\n",
    "        # ID to its centroid and number of consecutive frames it has been marked as \"disappeared\", respectively\n",
    "        self.nextObjectID = 0\n",
    "        self.objects = OrderedDict()\n",
    "        self.disappeared = OrderedDict()\n",
    "        # store the number of maximum consecutive frames a given object is allowed to be marked as \"disappeared\" until we\n",
    "        #need to deregister the object from tracking\n",
    "        self.maxDisappeared = maxDisappeared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def register(self, centroid):\n",
    "        # when registering an object we use the next available object\n",
    "        # ID to store the centroid\n",
    "        self.objects[self.nextObjectID] = centroid\n",
    "        self.disappeared[self.nextObjectID] = 0\n",
    "        self.nextObjectID += 1\n",
    "    def deregister(self, objectID):\n",
    "        # to deregister an object ID we delete the object ID from\n",
    "        # both of our respective dictionaries\n",
    "        del self.objects[objectID]\n",
    "        del self.disappeared[objectID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def update(self, rects):\n",
    "        # check to see if the list of input bounding box rectangles\n",
    "        # is empty\n",
    "        if len(rects) == 0:\n",
    "            # loop over any existing tracked objects and mark them\n",
    "            # as disappeared\n",
    "            for objectID in list(self.disappeared.keys()):\n",
    "                self.disappeared[objectID] += 1\n",
    "                # if we have reached a maximum number of consecutive\n",
    "                # frames where a given object has been marked as\n",
    "                # missing, deregister it\n",
    "                if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                    self.deregister(objectID)\n",
    "            # return early as there are no centroids or tracking info\n",
    "            # to update\n",
    "            return self.objects\n",
    "        # initialize an array of input centroids for the current frame\n",
    "        inputCentroids = np.zeros((len(rects), 2), dtype=\"int\")\n",
    "        # loop over the bounding box rectangles\n",
    "        for (i, (startX, startY, endX, endY)) in enumerate(rects):\n",
    "            # use the bounding box coordinates to derive the centroid\n",
    "            cX = int((startX + endX) / 2.0)\n",
    "            cY = int((startY + endY) / 2.0)\n",
    "            inputCentroids[i] = (cX, cY)\n",
    "        # if we are currently not tracking any objects take the input\n",
    "        # centroids and register each of them\n",
    "        if len(self.objects) == 0:\n",
    "            for i in range(0, len(inputCentroids)):\n",
    "                self.register(inputCentroids[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
